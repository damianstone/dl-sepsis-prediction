{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load and save a balanced background and eval set. background from the training set and eval from the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "QUICK_DEBUG = False\n",
    "MEDIUM_DEBUG = True\n",
    "RANDOM_STATE = SEED\n",
    "OUTPUT_FOLDER_NAME = \"final_datasets/shap\"\n",
    "BACKGROUND_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from final_pipeline import ModelWrapper, get_data, setup_device\n",
    "from full_pipeline import find_project_root\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from explain_model_helpers import ShapModel, get_config, get_patient_predictions, get_pred_threshold\n",
    "from preprocess import over_under_sample\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = find_project_root()\n",
    "data_output_folder = f\"{project_root}/dataset/{OUTPUT_FOLDER_NAME}\"\n",
    "if not os.path.exists(data_output_folder):\n",
    "    os.makedirs(data_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidend/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/Users/aidend/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/Users/aidend/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "project_root = find_project_root()\n",
    "results_name = \"medium_model_no_sampling\"\n",
    "config = get_config(project_root, results_name)\n",
    "\n",
    "device = setup_device()\n",
    "train_data = get_data(config, \"train\")\n",
    "val_data = get_data(config, \"val\")\n",
    "test_data = get_data(config, \"test\")\n",
    "in_dim = train_data.X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n",
      "(9611, 109)\n",
      "SepsisLabel\n",
      "1    100\n",
      "0    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "background_df = copy.deepcopy(train_data.df)\n",
    "\n",
    "background_patient_df = background_df.groupby(\"patient_id\")[\"SepsisLabel\"].max().reset_index()\n",
    "\n",
    "# Count patients in each group.\n",
    "counts = background_patient_df[\"SepsisLabel\"].value_counts()\n",
    "\n",
    "neg_patients = background_patient_df[background_patient_df[\"SepsisLabel\"] == 0]\n",
    "pos_patients = background_patient_df[background_patient_df[\"SepsisLabel\"] == 1]\n",
    "sampled_neg_patients = neg_patients.sample(n=BACKGROUND_SIZE // 2, replace=False, random_state=SEED)\n",
    "sampled_pos_patients = pos_patients.sample(n=BACKGROUND_SIZE // 2, replace=False, random_state=SEED)\n",
    "\n",
    "background_df = background_df[background_df[\"patient_id\"].isin(sampled_neg_patients[\"patient_id\"]) | background_df[\"patient_id\"].isin(sampled_pos_patients[\"patient_id\"])]\n",
    "\n",
    "print(background_df.shape)\n",
    "print(background_df.groupby(\"patient_id\")[\"SepsisLabel\"].max().value_counts())\n",
    "\n",
    "background_df.to_parquet(f\"{data_output_folder}/background.parquet\")\n",
    "\n",
    "# save the patient ids as json\n",
    "patient_ids = background_df[\"patient_id\"].unique()\n",
    "with open(f\"{data_output_folder}/background_patient_ids.json\", \"w\") as f:\n",
    "    json.dump(patient_ids.tolist(), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient-level balance statistics:\n",
      "Total patients: 1172\n",
      "Label 1: 586 patients (50.00%)\n",
      "Label 0: 586 patients (50.00%)\n",
      "Imbalance ratio (majority/minority): 1.00\n",
      "(57226, 109)\n",
      "SepsisLabel\n",
      "1    586\n",
      "0    586\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "eval_df = copy.deepcopy(test_data.df)\n",
    "eval_df = over_under_sample(eval_df, method=\"undersample\", minority_ratio=0.5, random_state=SEED)\n",
    "eval_df.to_parquet(f\"{data_output_folder}/eval.parquet\")\n",
    "\n",
    "patient_ids = eval_df[\"patient_id\"].unique()\n",
    "with open(f\"{data_output_folder}/eval_patient_ids.json\", \"w\") as f:\n",
    "    json.dump(patient_ids.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidend/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/Users/aidend/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "background_data = get_data(config, \"shap_background\")\n",
    "eval_data = get_data(config, \"shap_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_output_folder = f\"{project_root}/models/model_B/results/{config['xperiment']['name']}/shap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidend/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(config, device, in_dim)\n",
    "model.load_saved_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SHAP batches:   0%|          | 0/127 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m shap_model = ShapModel(model.model, train_data, device, pad_value=\u001b[32m0.0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m shap_vals, masks = \u001b[43mshap_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_shap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (64, 400, 107)\u001b[39;00m\n\u001b[32m      3\u001b[39m shap_model.save(shap_output_folder)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/ds_uni/dl-sepsis-prediction/models/model_B/explain_model_helpers.py:243\u001b[39m, in \u001b[36mget_shap_values\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    240\u001b[39m masks_lst: \u001b[38;5;28mlist\u001b[39m[np.ndarray] = []\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(loader, desc=\u001b[33m\"\u001b[39m\u001b[33mSHAP batches\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     xs, mask = to_batch_major_order(batch)\n\u001b[32m    244\u001b[39m     shap_values_lst.append(\u001b[38;5;28mself\u001b[39m.explainer.shap_values(xs))\n\u001b[32m    245\u001b[39m     masks_lst.append(mask.cpu().numpy())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/shap/explainers/_gradient.py:160\u001b[39m, in \u001b[36mGradientExplainer.shap_values\u001b[39m\u001b[34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mshap_values\u001b[39m(\n\u001b[32m    109\u001b[39m     \u001b[38;5;28mself\u001b[39m, X, nsamples=\u001b[32m200\u001b[39m, ranked_outputs=\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m, rseed=\u001b[38;5;28;01mNone\u001b[39;00m, return_variances=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    110\u001b[39m ):\n\u001b[32m    111\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the values for the model applied to X.\u001b[39;00m\n\u001b[32m    112\u001b[39m \n\u001b[32m    113\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \n\u001b[32m    159\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexplainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_variances\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/shap/explainers/_gradient.py:613\u001b[39m, in \u001b[36m_PyTorchGradient.shap_values\u001b[39m\u001b[34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, nsamples, \u001b[38;5;28mself\u001b[39m.batch_size):\n\u001b[32m    610\u001b[39m     batch = [\n\u001b[32m    611\u001b[39m         samples_input[c][b : \u001b[38;5;28mmin\u001b[39m(b + \u001b[38;5;28mself\u001b[39m.batch_size, nsamples)].clone().detach() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))\n\u001b[32m    612\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     grads.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    614\u001b[39m grad = [np.concatenate([g[z] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads], \u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.data))]\n\u001b[32m    615\u001b[39m \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/shap/explainers/_gradient.py:495\u001b[39m, in \u001b[36m_PyTorchGradient.gradient\u001b[39m\u001b[34m(self, idx, inputs)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layer.target_input\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    494\u001b[39m     grads = [\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].cpu().numpy()\n\u001b[32m    496\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X)\n\u001b[32m    497\u001b[39m     ]\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m grads\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:496\u001b[39m, in \u001b[36mgrad\u001b[39m\u001b[34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[39m\n\u001b[32m    492\u001b[39m     result = _vmap_internals._vmap(vjp, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, allow_none_pass_through=\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[32m    493\u001b[39m         grad_outputs_\n\u001b[32m    494\u001b[39m     )\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    507\u001b[39m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[32m    508\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[32m    509\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/ds_uni/dl-sepsis-prediction/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "shap_model = ShapModel(model.model, background_data, device, pad_value=0.0)\n",
    "shap_vals, masks = shap_model.get_shap_values(eval_data)  # (256, 400, 107)\n",
    "shap_model.save(shap_output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation simple encoder transformer\n",
    "- trained using a small balanced dataset\n",
    "- tested with original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "/Users/damianstone/Documents/Code/machine-learning/dl-sepsis-prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"../..\"))\n",
    "print(project_root)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "EVAL = \"03_simple_transformer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damianstone/Documents/Code/machine-learning/dl-sepsis-prediction/venv-sepsis/lib/python3.12/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    num_heads = more heads capture different attention but increase computation\n",
    "    num_layers = more make the model deeper but can overfit if too high\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, num_heads=4, num_layers=4):\n",
    "        super().__init__()\n",
    "        # d_model = input_dim (number of features)\n",
    "        # TODO: add drop out to avoid overfitting\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, nhead=num_heads)\n",
    "        # stacks multiple encoder layers (num_layers controls depth)\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layer, num_layers=num_layers)\n",
    "        # linear layer to map the output to a single value (binary classification)\n",
    "        self.linear_layer = nn.Linear(in_features=input_dim, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Output shape: (batch_size, seq_len, features) or (batch_size, features)\n",
    "        z = self.encoder(x)\n",
    "        if z.dim() == 3:  # If (batch_size, seq_len, features), take the last timestep\n",
    "            # NOTE: last timestep -> the most recent ICU data is usually the most relevant for prediction\n",
    "            z = z[:, -1, :]\n",
    "        return self.linear_layer(z)\n",
    "\n",
    "model = TransformerClassifier(input_dim=38, num_heads=2)\n",
    "model.load_state_dict(torch.load(\"./saved/03_simple_transformer.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved dataset tensors\n"
     ]
    }
   ],
   "source": [
    "from utils import get_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tensor_ds_path = f\"{project_root}/dataset/small_dataset_tensors.pth\"\n",
    "if os.path.exists(tensor_ds_path):\n",
    "    data = torch.load(tensor_ds_path)\n",
    "    print(\"Loaded saved dataset tensors\")\n",
    "    X_tensor = data[\"X_test\"] \n",
    "    y_tensor = data[\"y_test\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.50726 | Test Accuracy: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "batch_size = 512 \n",
    "test_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "test_loss, test_acc = 0, 0\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "t_accuracy = Accuracy(task='binary')\n",
    "all_y_logits, all_y_probs, all_y_pred, all_y_test = [], [], [], []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for X_batch, y_batch in progress_bar:\n",
    "        y_logits = model(X_batch)\n",
    "        y_probs = torch.sigmoid(y_logits)\n",
    "        y_pred = torch.round(y_probs)\n",
    "        \n",
    "        loss = loss_fn(y_logits, y_batch.unsqueeze(1).float())\n",
    "        acc = t_accuracy(y_pred, y_batch.unsqueeze(1).float())\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        test_acc += acc.item()\n",
    "        \n",
    "        progress_bar.set_postfix({\"Loss\": loss.item(), \"Acc\": acc.item()})\n",
    "        \n",
    "        all_y_logits.append(y_logits.cpu())\n",
    "        all_y_probs.append(y_probs.cpu())\n",
    "        all_y_pred.append(y_pred.cpu())\n",
    "        all_y_test.append(y_batch.cpu())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_acc /= len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.5f} | Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from t_utils import save_eval_csv\n",
    "\n",
    "all_y_logits = torch.cat(all_y_logits).numpy().flatten()\n",
    "all_y_probs = torch.cat(all_y_probs).numpy().flatten()\n",
    "all_y_pred = torch.cat(all_y_pred).numpy().flatten()\n",
    "all_y_test = torch.cat(all_y_test).numpy().astype(int) \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y_logits': all_y_logits,\n",
    "    'y_probs': all_y_probs,\n",
    "    'y_pred': all_y_pred,\n",
    "    'y_test': all_y_test\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_eval_csv(df, EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 77.69%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (df['y_pred'] == df['y_test']).mean() * 100\n",
    "print(f\"Total Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and plots\n",
    "- If false negatives are worse → Use best threshold (F1-optimized).\n",
    "- If false positives are worse → Use precision-optimized threshold.\n",
    "- If both are critical → Stick to best_threshold but adjust slightly based on results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type float32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      5\u001b[39m y_pred = df[\u001b[33m'\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m      7\u001b[39m save_plots(\n\u001b[32m      8\u001b[39m     y_test=y_test,\n\u001b[32m      9\u001b[39m     y_probs=y_probs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     attention_weights=[]\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43msave_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_probs\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mEVAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/machine-learning/dl-sepsis-prediction/models/model_B/t_utils.py:184\u001b[39m, in \u001b[36msave_metrics\u001b[39m\u001b[34m(y_test, y_probs, y_pred, eval)\u001b[39m\n\u001b[32m    174\u001b[39m metrics = {\n\u001b[32m    175\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAUC\u001b[39m\u001b[33m\"\u001b[39m: auc_score,\n\u001b[32m    176\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBest Threshold\u001b[39m\u001b[33m\"\u001b[39m: best_threshold,\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mClassification Report\u001b[39m\u001b[33m\"\u001b[39m: report,\n\u001b[32m    181\u001b[39m }\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(save_path, \u001b[33m\"\u001b[39m\u001b[33mmetrics.json\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMetrics saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/metrics.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:432\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    430\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:439\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type float32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "from t_utils import save_plots, FEATURE_NAMES, save_metrics\n",
    "\n",
    "y_test = df['y_test'].values\n",
    "y_probs = df['y_probs'].values\n",
    "y_pred = df['y_pred'].values\n",
    "\n",
    "save_plots(\n",
    "    y_test=y_test,\n",
    "    y_probs=y_probs,\n",
    "    y_pred=y_pred,\n",
    "    model=model, \n",
    "    feature_names=FEATURE_NAMES,\n",
    "    eval=EVAL,\n",
    "    attention_weights=[]\n",
    ")\n",
    "\n",
    "save_metrics(\n",
    "    y_test=y_test,\n",
    "    y_probs=y_probs,\n",
    "    y_pred=y_pred,\n",
    "    eval=EVAL,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-sepsis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

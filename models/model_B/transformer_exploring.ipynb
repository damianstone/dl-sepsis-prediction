{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring transformers architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "/Users/damianstone/Documents/Code/machine-learning/dl-sepsis-prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"../..\"))\n",
    "print(project_root)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_data\n",
    "\n",
    "DATA_PATH = get_data.get_dataset_abspath()\n",
    "load_path = os.path.join(DATA_PATH, \"imputed_combined_data.parquet\")\n",
    "imputed_df = pd.read_parquet(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>FiO2</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102.108491</td>\n",
       "      <td>91.419811</td>\n",
       "      <td>36.789519</td>\n",
       "      <td>128.165094</td>\n",
       "      <td>88.199717</td>\n",
       "      <td>71.73211</td>\n",
       "      <td>24.712264</td>\n",
       "      <td>-0.288406</td>\n",
       "      <td>23.835971</td>\n",
       "      <td>0.467029</td>\n",
       "      <td>...</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.715787</td>\n",
       "      <td>0.284213</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0_9_2_2_X_X_X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           HR      O2Sat       Temp         SBP        MAP       DBP  \\\n",
       "0  102.108491  91.419811  36.789519  128.165094  88.199717  71.73211   \n",
       "\n",
       "        Resp  BaseExcess       HCO3      FiO2  ...    Age  Gender     Unit1  \\\n",
       "0  24.712264   -0.288406  23.835971  0.467029  ...  83.14       0  0.715787   \n",
       "\n",
       "      Unit2  HospAdmTime  ICULOS  SepsisLabel  patient_id  dataset  \\\n",
       "0  0.284213        -0.03       1            0           1        A   \n",
       "\n",
       "      cluster_id  \n",
       "0  0_9_2_2_X_X_X  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column doesn't exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'BaseExcess',\n",
       "       'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos',\n",
       "       'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct', 'Glucose',\n",
       "       'Lactate', 'Magnesium', 'Phosphate', 'Potassium', 'Bilirubin_total',\n",
       "       'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC', 'Fibrinogen', 'Platelets',\n",
       "       'Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS',\n",
       "       'SepsisLabel', 'patient_id', 'dataset', 'cluster_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'SOFA' in imputed_df.columns:\n",
    "    print(\"Column exists.\")\n",
    "else:\n",
    "    print(\"Column doesn't exist.\")\n",
    "    \n",
    "imputed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>FiO2</th>\n",
       "      <th>...</th>\n",
       "      <th>PTT</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>SOFA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102.108491</td>\n",
       "      <td>91.419811</td>\n",
       "      <td>36.789519</td>\n",
       "      <td>128.165094</td>\n",
       "      <td>88.199717</td>\n",
       "      <td>71.73211</td>\n",
       "      <td>24.712264</td>\n",
       "      <td>-0.288406</td>\n",
       "      <td>23.835971</td>\n",
       "      <td>0.467029</td>\n",
       "      <td>...</td>\n",
       "      <td>36.405357</td>\n",
       "      <td>11.737903</td>\n",
       "      <td>350.0</td>\n",
       "      <td>224.187135</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           HR      O2Sat       Temp         SBP        MAP       DBP  \\\n",
       "0  102.108491  91.419811  36.789519  128.165094  88.199717  71.73211   \n",
       "\n",
       "        Resp  BaseExcess       HCO3      FiO2  ...        PTT        WBC  \\\n",
       "0  24.712264   -0.288406  23.835971  0.467029  ...  36.405357  11.737903   \n",
       "\n",
       "   Fibrinogen   Platelets    Age  Gender  HospAdmTime  ICULOS  SepsisLabel  \\\n",
       "0       350.0  224.187135  83.14       0        -0.03       1            0   \n",
       "\n",
       "   SOFA  \n",
       "0     2  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOFA calculation based on Sepsis-3\n",
    "def calculate_sofa(row):\n",
    "    sofa = 0\n",
    "    \n",
    "    if row['FiO2'] > 0:\n",
    "        pao2_fio2 = row['SaO2'] / row['FiO2']\n",
    "        if pao2_fio2 < 100: sofa += 4\n",
    "        elif pao2_fio2 < 200: sofa += 3\n",
    "        elif pao2_fio2 < 300: sofa += 2\n",
    "        elif pao2_fio2 < 400: sofa += 1\n",
    "\n",
    "    if row['Platelets'] < 20: sofa += 4\n",
    "    elif row['Platelets'] < 50: sofa += 3\n",
    "    elif row['Platelets'] < 100: sofa += 2\n",
    "    elif row['Platelets'] < 150: sofa += 1\n",
    "\n",
    "    if row['Bilirubin_total'] >= 12: sofa += 4\n",
    "    elif row['Bilirubin_total'] >= 6: sofa += 3\n",
    "    elif row['Bilirubin_total'] >= 2: sofa += 2\n",
    "    elif row['Bilirubin_total'] >= 1.2: sofa += 1\n",
    "\n",
    "    if row['MAP'] < 70: sofa += 1\n",
    "\n",
    "    if row['Creatinine'] >= 5: sofa += 4\n",
    "    elif row['Creatinine'] >= 3.5: sofa += 3\n",
    "    elif row['Creatinine'] >= 2: sofa += 2\n",
    "    elif row['Creatinine'] >= 1.2: sofa += 1\n",
    "\n",
    "    return sofa\n",
    "\n",
    "imputed_df = imputed_df.drop(columns=[\"Unit1\", \"Unit2\", \"cluster_id\",\"dataset\", \"patient_id\"], errors='ignore')\n",
    "imputed_df = imputed_df.dropna(subset=[\"HospAdmTime\"])\n",
    "imputed_df[\"SOFA\"] = imputed_df.apply(calculate_sofa, axis=1)\n",
    "imputed_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HR                  0\n",
       "O2Sat               0\n",
       "Temp                0\n",
       "SBP                 0\n",
       "MAP                 0\n",
       "DBP                 0\n",
       "Resp                0\n",
       "BaseExcess          0\n",
       "HCO3                0\n",
       "FiO2                0\n",
       "pH                  0\n",
       "PaCO2               0\n",
       "SaO2                0\n",
       "AST                 0\n",
       "BUN                 0\n",
       "Alkalinephos        0\n",
       "Calcium             0\n",
       "Chloride            0\n",
       "Creatinine          0\n",
       "Bilirubin_direct    0\n",
       "Glucose             0\n",
       "Lactate             0\n",
       "Magnesium           0\n",
       "Phosphate           0\n",
       "Potassium           0\n",
       "Bilirubin_total     0\n",
       "TroponinI           0\n",
       "Hct                 0\n",
       "Hgb                 0\n",
       "PTT                 0\n",
       "WBC                 0\n",
       "Fibrinogen          0\n",
       "Platelets           0\n",
       "Age                 0\n",
       "Gender              0\n",
       "HospAdmTime         0\n",
       "ICULOS              0\n",
       "SepsisLabel         0\n",
       "SOFA                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df.to_parquet(f\"{project_root}/dataset/imputed_sofa.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_splitted_data import get_dataset_tensors\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_dataset_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer architecture\n",
    "- Use `Mean Pooling` (x.mean(dim=1)) if: You want a summary of the whole sequence (useful if sepsis patterns are spread across time).\n",
    "- Use `Max Pooling` (x.max(dim=1).values) if: You want to focus on the most extreme feature values, which might indicate critical moments.\n",
    "- Use `Last Timestep` (x[:, -1, :]) if: You believe the latest patient state matters most (recommended for your case).\n",
    "\n",
    "Test pooling:\n",
    "- Train with different pooling methods and compare AUC-ROC scores.\n",
    "- If AUC increases, the new pooling method is better.\n",
    "- Visualize attention weights to see where the model is focusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damianstone/Documents/Code/machine-learning/dl-sepsis-prediction/venv-sepsis/lib/python3.12/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    num_heads = more heads capture different attention but increase computation\n",
    "    num_layers = more make the model deeper but can overfit if too high\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_heads=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        # d_model = input_dim (number of features)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads)\n",
    "        # stacks multiple encoder layers (num_layers controls depth)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        # linear layer to map the output to a single value (binary classification)\n",
    "        self.linear_layer = nn.Linear(in_features=input_dim, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "      z = self.encoder(x)  # Output shape: (batch_size, seq_len, features) or (batch_size, features)\n",
    "      if z.dim() == 3:  # If (batch_size, seq_len, features), take the last timestep\n",
    "            # NOTE: last timestep -> the most recent ICU data is usually the most relevant for prediction\n",
    "            z = z[:, -1, :]\n",
    "      return self.linear_layer(z)\n",
    "\n",
    "\n",
    "def get_valid_num_heads(input_dim, desired_heads):\n",
    "    \"\"\"Finds the highest valid num_heads <= desired_heads that divides input_dim.\"\"\"\n",
    "    while desired_heads > 0 and input_dim % desired_heads != 0:\n",
    "        desired_heads -= 1\n",
    "    return max(1, desired_heads)\n",
    "\n",
    "\n",
    "in_dim = X_train.shape[1]\n",
    "print(in_dim)\n",
    "n_heads = get_valid_num_heads(in_dim, 10)\n",
    "print(n_heads)\n",
    "model = TransformerClassifier(input_dim=in_dim, num_heads=n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(X_test.dtype)  # Ensure it prints torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0394],\n",
       "        [-1.3452],\n",
       "        [-1.1834],\n",
       "        [-1.0828],\n",
       "        [-0.7410]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "y_pred_list = []\n",
    "with torch.inference_mode():\n",
    "    for i in range(0, len(X_test), batch_size):\n",
    "        batch = X_test[i:i+batch_size]\n",
    "        y_pred_list.append(model(batch))\n",
    "y_pred = torch.cat(y_pred_list)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 512 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/2426 [03:16<?, ?it/s, Loss=0.116, Acc=0.975] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Loss: 0.08523 | Accuracy: 0.98%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "model = TransformerClassifier(input_dim=in_dim, num_heads=n_heads)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001) \n",
    "\n",
    "epochs = 1\n",
    "epoch_counter = []\n",
    "loss_counter = []\n",
    "acc_counter = []\n",
    "\n",
    "t_accuracy = Accuracy(task='binary')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss, epoch_acc = 0, 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # forward pass\n",
    "        y_logits = model(X_batch)\n",
    "        y_probs = torch.sigmoid(y_logits)\n",
    "        y_pred = torch.round(y_probs)\n",
    "\n",
    "        # loss function\n",
    "        loss = loss_fn(y_logits, y_batch.unsqueeze(1).float())\n",
    "        acc = t_accuracy(y_pred, y_batch.unsqueeze(1).float())\n",
    "        \n",
    "        # zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # optimizer\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # clip gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "        \n",
    "        progress_bar.set_postfix({\"Loss\": loss.item(), \"Acc\": acc.item()})\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_acc /= len(train_loader)\n",
    "    acc_counter.append(epoch_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.5f} | Accuracy: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# save the model\n",
    "model_path = Path('./saved')\n",
    "model_path.mkdir(exist_ok=True)\n",
    "model_file = model_path / 'simple_transformer.pth'\n",
    "\n",
    "torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damianstone/Documents/Code/machine-learning/dl-sepsis-prediction/venv-sepsis/lib/python3.12/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerClassifier(input_dim=in_dim, num_heads=n_heads)\n",
    "model.load_state_dict(torch.load(\"./saved/simple_transformer.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-sepsis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "file_path = \"dataset/imputed_combined_data.parquet\" \n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "df.head()\n",
    "\n",
    "max_length = df.groupby(\"patient_id\").size().max()\n",
    "\n",
    "# SOFA Score Calculation\n",
    "def calculate_sofa(row):\n",
    "    sofa = 0\n",
    "\n",
    "    def assign_score(value, thresholds):\n",
    "        for threshold, score in thresholds:\n",
    "            if value >= threshold:\n",
    "                return score\n",
    "        return 0  \n",
    "\n",
    "    # Respiration \n",
    "    if row.get('FiO2', 0) > 0:\n",
    "        pao2_fio2 = row.get('SaO2', 0) / row['FiO2']\n",
    "        sofa += assign_score(pao2_fio2, [(100, 4), (200, 3), (300, 2), (400, 1)])\n",
    "\n",
    "    # Coagulation\n",
    "    sofa += assign_score(row.get('Platelets', float('inf')), [(20, 4), (50, 3), (100, 2), (150, 1)])\n",
    "\n",
    "    # Liver Function\n",
    "    sofa += assign_score(row.get('Bilirubin_total', 0), [(12, 4), (6, 3), (2, 2), (1.2, 1)])\n",
    "\n",
    "    # Cardiovascular\n",
    "    if row.get('MAP', 100) < 70:\n",
    "        sofa += 1\n",
    "\n",
    "    # Renal Function\n",
    "    sofa += assign_score(row.get('Creatinine', 0), [(5, 4), (3.5, 3), (2, 2), (1.2, 1)])\n",
    "\n",
    "    return sofa\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    #Adds rolling statistics (moving averages, standard deviation, rate of change) for some features (may or may not be useful).\n",
    "    time_window_sizes = [3, 6, 12]  # Rolling window sizes (in time steps)\n",
    "    feature_cols = ['HeartRate', 'RespiratoryRate', 'MAP', 'SpO2', 'Creatinine', 'Platelets']\n",
    "\n",
    "    df.sort_values(['patient_id', 'ICULOS'], inplace=True)\n",
    "\n",
    "    for col in feature_cols:\n",
    "        if col in df.columns:\n",
    "            for window in time_window_sizes:\n",
    "                df[f'{col}_MA_{window}h'] = df.groupby('patient_id')[col].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "                df[f'{col}_SD_{window}h'] = df.groupby('patient_id')[col].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "                df[f'{col}_Delta'] = df.groupby('patient_id')[col].diff()\n",
    "    return df\n",
    "\n",
    "def preprocess_data(output_file):\n",
    "    global df \n",
    "\n",
    "    df['SOFA'] = df.apply(calculate_sofa, axis=1)\n",
    "    df = add_temporal_features(df)\n",
    "\n",
    "    if 'Gender' in df.columns:\n",
    "        df['Gender'] = LabelEncoder().fit_transform(df['Gender'].astype(str))\n",
    "\n",
    "    feature_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    scaler = MinMaxScaler()\n",
    "    df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "    # Process each patient separately\n",
    "    padded_data_list = []\n",
    "    patient_ids = df['patient_id'].unique()\n",
    "\n",
    "    for patient_id in patient_ids:\n",
    "        patient_data = df[df['patient_id'] == patient_id]\n",
    "        sequence_length = len(patient_data)\n",
    "\n",
    "        # Pad patient's data to max_length\n",
    "        padded_patient_data = np.zeros((max_length, len(feature_cols)))\n",
    "        padded_patient_data[:sequence_length, :] = patient_data[feature_cols].values\n",
    "\n",
    "        if sequence_length < max_length:\n",
    "            last_entry = padded_patient_data[sequence_length - 1]  # Last valid row\n",
    "            padded_patient_data[sequence_length:, :] = last_entry  # Fill with last row\n",
    "\n",
    "        padded_data_list.append(padded_patient_data)\n",
    "\n",
    "    # Convert list to DataFrame and save\n",
    "    padded_df = pd.DataFrame(np.concatenate(padded_data_list, axis=0), columns=feature_cols)\n",
    "    padded_df.to_parquet(output_file, index=False)\n",
    "\n",
    "    print(f\"Preprocessed data saved to {output_file}\")\n",
    "\n",
    "output_file = \"preprocessed_data.parquet\"\n",
    "preprocess_data(output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

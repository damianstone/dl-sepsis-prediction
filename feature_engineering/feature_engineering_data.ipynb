{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below for the FULL feature engineered file with SOFA, NEWS, qSOFA, temporal sliding windows. If you're wanting feature reduction you need to also run the ones below this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_project_root(marker=\".gitignore\"):\n",
    "    \"\"\"\n",
    "    walk up from the current working directory until a directory containing the\n",
    "    specified marker (e.g., .gitignore) is found.\n",
    "    \"\"\"\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / marker).exists():\n",
    "            return parent.resolve()\n",
    "    raise FileNotFoundError(f\"Project root marker '{marker}' not found starting from {current}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive patients: 2932\n",
      "Number of negative patients: 37404\n",
      "save to: C:\\Users\\Administrator\\Desktop\\ds\\dl-sepsis-prediction\\dataset\\feature_engineering\\balanced_dataset.parquet\n",
      "retained positive patients: 2932\n",
      "retained negative patients: 6841\n",
      "Positive ratio: 0.3000102322725877\n"
     ]
    }
   ],
   "source": [
    "root = find_project_root()\n",
    "INPUT_DATASET = f\"{root}/dataset/Fully_imputed_dataset.parquet\"\n",
    "OUTPUT_DATASET = f\"{root}/dataset/preprocessed_data.parquet\"\n",
    "BALANCED_INPUT = f\"{root}/dataset/feature_engineering/balanced_dataset.parquet\"\n",
    "\n",
    "\n",
    "\n",
    "def create_balanced_dataset(\n",
    "    input_file=INPUT_DATASET, output_file=\"balanced_dataset.parquet\"):\n",
    "    root = find_project_root()\n",
    "    data_path = root / \"dataset\" / input_file\n",
    "    df = pd.read_parquet(data_path)\n",
    "\n",
    "    if not isinstance(df.index, pd.MultiIndex):\n",
    "        df.set_index([\"patient_id\", \"ICULOS\"], inplace=True)\n",
    "\n",
    "    grouped = df.reset_index().groupby(\"patient_id\")[\"SepsisLabel\"]\n",
    "    patient_is_positive = grouped.max()\n",
    "\n",
    "    positive_ids = patient_is_positive[patient_is_positive == 1].index\n",
    "    negative_ids = patient_is_positive[patient_is_positive == 0].index\n",
    "\n",
    "    print(f\"Number of positive patients: {len(positive_ids)}\")\n",
    "    print(f\"Number of negative patients: {len(negative_ids)}\")\n",
    "\n",
    "    np.random.seed(1)\n",
    "    sampled_negative_ids = np.random.choice( negative_ids, size=int(len(positive_ids) * (70 / 30)), replace=False)\n",
    "    keep_ids = set(positive_ids).union(set(sampled_negative_ids))\n",
    "    df_balanced = df.loc[df.index.get_level_values(\"patient_id\").isin(keep_ids)]\n",
    "\n",
    "    out_path = root / \"dataset\" / \"feature_engineering\"/output_file\n",
    "    df_balanced.to_parquet(out_path)\n",
    "    print(f\"save to: {out_path}\")\n",
    "\n",
    "    final_label_map = (\n",
    "        df_balanced.reset_index().groupby(\"patient_id\")[\"SepsisLabel\"].max()\n",
    "    )\n",
    "\n",
    "    final_positive = (final_label_map == 1).sum()\n",
    "    final_negative = (final_label_map == 0).sum()\n",
    "\n",
    "    print(f\"retained positive patients: {final_positive}\")\n",
    "    print(f\"retained negative patients: {final_negative}\")\n",
    "    print(f\"Positive ratio: {final_positive / (final_positive + final_negative)}\")\n",
    "\n",
    "create_balanced_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swifter in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from swifter) (2.2.3)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from swifter) (7.0.0)\n",
      "Requirement already satisfied: dask>=2.10.0 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2025.3.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from swifter) (4.67.1)\n",
      "Requirement already satisfied: click>=8.1 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (24.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.6.1)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (19.0.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from pandas>=1.0.0->swifter) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from tqdm>=4.33.0->swifter) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from importlib_metadata>=4.13.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.21.0)\n",
      "Requirement already satisfied: locket in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\.conda\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 424368/424368 [00:07<00:00, 53047.24it/s]\n",
      "Pandas Apply: 100%|██████████| 424368/424368 [00:07<00:00, 55424.16it/s]\n",
      "Pandas Apply: 100%|██████████| 424368/424368 [00:03<00:00, 127677.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 163\u001b[0m\n\u001b[0;32m    159\u001b[0m     preview\u001b[38;5;241m.\u001b[39mto_csv(preview_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreview of patient saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreview_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 163\u001b[0m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_DATASET\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 136\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(output_file)\u001b[0m\n\u001b[0;32m    133\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqSOFA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mswifter\u001b[38;5;241m.\u001b[39mapply(calculate_qsofa, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m#df['num_recorded_values'] = df.apply(num_recorded_values, axis=1)\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m#df['missingness_feature'] = df.apply(missingness_feature, axis=1)\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43madd_temporal_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m physio_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO2Sat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreatinine\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlatelets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    141\u001b[0m cols_to_normalize \u001b[38;5;241m=\u001b[39m physio_cols\n",
      "Cell \u001b[1;32mIn[19], line 117\u001b[0m, in \u001b[0;36madd_temporal_features\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m window \u001b[38;5;129;01min\u001b[39;00m time_window_sizes:\n\u001b[0;32m    116\u001b[0m     rolling \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m)[col]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mrolling(window, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 117\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mean_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrolling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_max_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rolling\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m    119\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_last_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rolling\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6548\u001b[0m ):\n\u001b[1;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12422\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    716\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\numpy\\_core\\_methods.py:52\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\series.py:6134\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m-> 6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_for_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base\u001b[38;5;241m.\u001b[39mIndexOpsMixin\u001b[38;5;241m.\u001b[39m_arith_method(\u001b[38;5;28mself\u001b[39m, other, op)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\series.py:6164\u001b[0m, in \u001b[0;36mSeries._align_for_op\u001b[1;34m(self, right, align_asobject)\u001b[0m\n\u001b[0;32m   6161\u001b[0m             left \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m   6162\u001b[0m             right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m-> 6164\u001b[0m         left, right \u001b[38;5;241m=\u001b[39m \u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   6166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m left, right\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:10447\u001b[0m, in \u001b[0;36mNDFrame.align\u001b[1;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[0;32m  10434\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_frame(\n\u001b[0;32m  10435\u001b[0m         other,\n\u001b[0;32m  10436\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10443\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[0;32m  10444\u001b[0m     )\n\u001b[0;32m  10446\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCSeries):\n\u001b[1;32m> 10447\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10450\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10457\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m  10459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:10564\u001b[0m, in \u001b[0;36mNDFrame._align_series\u001b[1;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[0;32m  10562\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m  10563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 10564\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_indexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m  10566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_series:\n\u001b[0;32m  10569\u001b[0m     left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_indexer(join_index, lidx, copy)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:279\u001b[0m, in \u001b[0;36m_maybe_return_indexers.<locals>.join\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(meth)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjoin\u001b[39m(\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    278\u001b[0m ):\n\u001b[1;32m--> 279\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_indexers:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m join_index\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4659\u001b[0m, in \u001b[0;36mIndex.join\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m   4656\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m other\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_join_non_unique(other, how\u001b[38;5;241m=\u001b[39mhow, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[1;32m-> 4659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_join_via_get_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4716\u001b[0m, in \u001b[0;36mIndex._join_via_get_indexer\u001b[1;34m(self, other, how, sort)\u001b[0m\n\u001b[0;32m   4714\u001b[0m     lindexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4716\u001b[0m     lindexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m join_index \u001b[38;5;129;01mis\u001b[39;00m other:\n\u001b[0;32m   4718\u001b[0m     rindexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6182\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6165\u001b[0m \u001b[38;5;124;03mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[0;32m   6166\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6179\u001b[0m \u001b[38;5;124;03marray([0, 2])\u001b[39;00m\n\u001b[0;32m   6180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 6182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6183\u001b[0m indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n\u001b[0;32m   6184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3953\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3948\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m this\u001b[38;5;241m.\u001b[39m_get_indexer(\n\u001b[0;32m   3950\u001b[0m         target, method\u001b[38;5;241m=\u001b[39mmethod, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m   3951\u001b[0m     )\n\u001b[1;32m-> 3953\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3980\u001b[0m, in \u001b[0;36mIndex._get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3978\u001b[0m         tgt_values \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39m_get_engine_target()\n\u001b[1;32m-> 3980\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "import swifter\n",
    "\n",
    "root = find_project_root()\n",
    "INPUT_DATASET = f\"{root}/dataset/Fully_imputed_dataset.parquet\"\n",
    "OUTPUT_DATASET = f\"{root}/dataset/preprocessed_data.parquet\"\n",
    "BALANCED_INPUT = f\"{root}/dataset/feature_engineering/balanced_dataset.parquet\"\n",
    "\n",
    "    \n",
    "df = pd.read_parquet(BALANCED_INPUT)\n",
    "df.head()\n",
    "max_length = df.groupby(\"patient_id\").size().max()\n",
    "\n",
    "# Score Calculation\n",
    "def calculate_sofa(row):\n",
    "    sofa = 0\n",
    "\n",
    "    def assign_score(value, thresholds):\n",
    "        for threshold, score in thresholds:\n",
    "            if value >= threshold:\n",
    "                return score\n",
    "        return 0  \n",
    "\n",
    "    # Respiration \n",
    "    if row.get('FiO2', 0) > 0:\n",
    "        pao2_fio2 = row.get('SaO2', 0) / row['FiO2']\n",
    "        sofa += assign_score(pao2_fio2, [(100, 4), (200, 3), (300, 2), (400, 1)])\n",
    "\n",
    "    # Coagulation\n",
    "    sofa += assign_score(row.get('Platelets', float('inf')), [(20, 4), (50, 3), (100, 2), (150, 1)])\n",
    "\n",
    "    # Liver Function\n",
    "    sofa += assign_score(row.get('Bilirubin_total', 0), [(12, 4), (6, 3), (2, 2), (1.2, 1)])\n",
    "\n",
    "    # Cardiovascular\n",
    "    if row.get('MAP', 100) < 70:\n",
    "        sofa += 1\n",
    "\n",
    "    # Renal Function\n",
    "    sofa += assign_score(row.get('Creatinine', 0), [(5, 4), (3.5, 3), (2, 2), (1.2, 1)])\n",
    "\n",
    "    return sofa\n",
    "\n",
    "def calculate_news(row):\n",
    "    news = 0\n",
    "\n",
    "    def assign_news_score(value, thresholds):\n",
    "        for threshold, score in thresholds:\n",
    "            if value >= threshold:\n",
    "                return score\n",
    "        return 0  \n",
    "\n",
    "    # HR (Heart Rate)\n",
    "    news += assign_news_score(row.get('HR', 0), [(40, 3), (50, 1), (90, 0), (110, 1), (130, 2), (131, 3)])\n",
    "\n",
    "    # Respiration Rate\n",
    "    news += assign_news_score(row.get('Resp', 0), [(8, 3), (9, 1), (11, 0), (21, 2), (24, 3)])\n",
    "\n",
    "    # Temperature\n",
    "    news += assign_news_score(row.get('Temp', 0), [(35, 3), (36, 1), (38, 1), (39.1, 2)])\n",
    "\n",
    "    # SBP (Systolic BP) or MAP (Mean Arterial Pressure)\n",
    "    sbp = row.get('SBP', row.get('MAP', 100))\n",
    "    news += assign_news_score(sbp, [(90, 3), (100, 2), (110, 1)])\n",
    "\n",
    "    # O2 Saturation\n",
    "    news += assign_news_score(row.get('O2Sat', 0), [(85, 3), (91, 2), (93, 1)])\n",
    "\n",
    "    # Supplemental Oxygen (if available)\n",
    "    if row.get('FiO2', 0) > 0.21:\n",
    "        news += 2\n",
    "\n",
    "    return news\n",
    "\n",
    "def calculate_qsofa(row):\n",
    "    qsofa = 0\n",
    "\n",
    "    # SBP ≤ 100 mmHg\n",
    "    if row.get('SBP', 120) <= 100:\n",
    "        qsofa += 1\n",
    "\n",
    "    # Respiration Rate ≥ 22\n",
    "    if row.get('Resp', 0) >= 22:\n",
    "        qsofa += 1\n",
    "\n",
    "    return qsofa\n",
    "\n",
    "def num_recorded_values(row):\n",
    "    recorded_measurements = df.notnull().sum()\n",
    "\n",
    "    return recorded_measurements\n",
    "\n",
    "def missingness_feature(row):\n",
    "    \n",
    "    if 'ICULOS' and 'ICULOS' in df.columns:\n",
    "        df = df.sort_values(by='ICULOS')\n",
    "        time_intervals = df['ICULOS'].diff()\n",
    "\n",
    "    return time_intervals\n",
    "\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    time_window_sizes = [3,6,12]\n",
    "    feature_cols = [\"HR\", \"Resp\", \"Temp\"]\n",
    "\n",
    "    df.sort_values(['patient_id', 'ICULOS'], inplace=True)\n",
    "\n",
    "    for col in feature_cols:\n",
    "        if col in df.columns:\n",
    "            for window in time_window_sizes:\n",
    "                rolling = df.groupby('patient_id')[col].transform(lambda x: x.rolling(window, min_periods=1))\n",
    "                df[f'{col}_mean_{window}h'] = rolling.mean()\n",
    "                df[f'{col}_max_{window}h'] = rolling.max()\n",
    "                df[f'{col}_last_{window}h'] = rolling.apply(lambda x: x.iloc[-1] if len(x) > 0 else np.nan, raw=False)\n",
    "\n",
    "    rolling_cols = [col for col in df.columns if any(stat in col for stat in [\"_mean_\", \"_max_\", \"_last_\"])]\n",
    "    df[rolling_cols] = df[rolling_cols].fillna(0)\n",
    "    df = df[df['ICULOS'] >= 11]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(output_file):\n",
    "    global df \n",
    "\n",
    "    df['SOFA'] = df.swifter.apply(calculate_sofa, axis=1)\n",
    "    df['NEWS'] = df.swifter.apply(calculate_news, axis=1)\n",
    "    df['qSOFA'] = df.swifter.apply(calculate_qsofa, axis=1)\n",
    "    #df['num_recorded_values'] = df.apply(num_recorded_values, axis=1)\n",
    "    #df['missingness_feature'] = df.apply(missingness_feature, axis=1)\n",
    "    df = add_temporal_features(df)\n",
    "    \n",
    "    \n",
    "    # drop columns that are not needed\n",
    "    columns_to_drop = [\"Unit1\", \"Unit2\", \"cluster_id\", \"dataset\", \"HospAdmTime\"]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # NOTE: handle nan values doing forward fill and then back fill\n",
    "    df = df.fillna(method=\"ffill\")\n",
    "    df = df.fillna(method=\"bfill\")\n",
    "\n",
    "    df.to_parquet(output_file, index=False)\n",
    "\n",
    "    print(f\"Preprocessed data saved to {output_file}\")\n",
    "    sample_patient_id = df['patient_id'].unique()[0]\n",
    "    preview = df[df['patient_id'] == sample_patient_id]\n",
    "    preview_path = str(output_file).replace(\".parquet\", \"_preview.csv\")\n",
    "    preview.to_csv(preview_path, index=False)\n",
    "    print(f\"Preview of patient saved to: {preview_path}\")\n",
    "\n",
    "\n",
    "preprocess_data(OUTPUT_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "If you're wanting the PCA analysis dataset run the code below to save it as pca_preprocessed.parquet in YOUR files (Github says file too large now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "root = find_project_root()\n",
    "INPUT_DATASET = f\"{root}/dataset/preprocessed_data.parquet\"\n",
    "OUTPUT_DATASET = f\"{root}/dataset/pca_preprocessed_data.parquet\"\n",
    "\n",
    "df = pd.read_parquet(INPUT_DATASET)\n",
    "\n",
    "keep_columns = [\"SepsisLabel\", \"patient_id\"]\n",
    "stored_columns = df[keep_columns].copy()\n",
    "\n",
    "# PCA process\n",
    "X = df.drop(columns=keep_columns)\n",
    "print(X.var())\n",
    "print(X.dtypes)\n",
    "y = df[\"SepsisLabel\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Original Features: {X.shape[1]}, Reduced Features: {X_pca.shape[1]}\")\n",
    "print(X_pca)\n",
    "\n",
    "# Plot\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.cumsum(explained_variance_ratio), marker=\"o\", linestyle=\"--\")\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA Explained Variance\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Create final DataFrame with all columns\n",
    "X_pca_df = pd.DataFrame(X_pca)\n",
    "# Add back the stored columns\n",
    "for col in keep_columns:\n",
    "    X_pca_df[col] = stored_columns[col]\n",
    "\n",
    "# Save complete DataFrame\n",
    "X_pca_df.to_parquet(OUTPUT_DATASET, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "Run below for feature selection, this is based on SHAP values + preliminary model training to see which features were most impactful + what is the optimal number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"preprocessed_data.parquet\" \n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "X = df.drop(columns=[\"SepsisLabel\", \"patient_id\", \"dataset\", \"cluster_id\", \"Unit2\", \"Gender\", \"Platelets_Delta\", \"Creatinine_Delta\", \"Platelets_SD_3h\", \"Hct\", \"MAP_Delta\", \"MAP_SD_3h\", \"Creatinine_MA_3h\", \"Creatinine_SD_3h\", \"Platelets\"])\n",
    "X = X.fillna(method=\"bfill\")\n",
    "X.to_parquet(\"feature_selection_preprocessed.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to preprocessed_data.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_project_root(marker=\".gitignore\"):\n",
    "    \"\"\"\n",
    "    walk up from the current working directory until a directory containing the\n",
    "    specified marker (e.g., .gitignore) is found.\n",
    "    \"\"\"\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / marker).exists():\n",
    "            return parent.resolve()\n",
    "    raise FileNotFoundError(f\"Project root marker '{marker}' not found starting from {current}\")\n",
    "\n",
    "\n",
    "root = find_project_root()\n",
    "\n",
    "file_path = f\"{root}/dataset/imputed_combined_data.parquet\" \n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "file_path_NANS = f\"{root}/dataset/raw_combined_data.parquet\"\n",
    "df2 = pd.read_parquet(file_path_NANS)\n",
    "\n",
    "df.head()\n",
    "\n",
    "max_length = df.groupby(\"patient_id\").size().max()\n",
    "\n",
    "# Score Calculation\n",
    "def calculate_sofa(row):\n",
    "    sofa = 0\n",
    "\n",
    "    def assign_score(value, thresholds):\n",
    "        for threshold, score in thresholds:\n",
    "            if value >= threshold:\n",
    "                return score\n",
    "        return 0  \n",
    "\n",
    "    # Respiration \n",
    "    if row.get('FiO2', 0) > 0:\n",
    "        pao2_fio2 = row.get('SaO2', 0) / row['FiO2']\n",
    "        sofa += assign_score(pao2_fio2, [(100, 4), (200, 3), (300, 2), (400, 1)])\n",
    "\n",
    "    # Coagulation\n",
    "    sofa += assign_score(row.get('Platelets', float('inf')), [(20, 4), (50, 3), (100, 2), (150, 1)])\n",
    "\n",
    "    # Liver Function\n",
    "    sofa += assign_score(row.get('Bilirubin_total', 0), [(12, 4), (6, 3), (2, 2), (1.2, 1)])\n",
    "\n",
    "    # Cardiovascular\n",
    "    if row.get('MAP', 100) < 70:\n",
    "        sofa += 1\n",
    "\n",
    "    # Renal Function\n",
    "    sofa += assign_score(row.get('Creatinine', 0), [(5, 4), (3.5, 3), (2, 2), (1.2, 1)])\n",
    "\n",
    "    return sofa\n",
    "\n",
    "def calculate_news(row):\n",
    "    news = 0\n",
    "\n",
    "    def assign_news_score(value, thresholds):\n",
    "        for threshold, score in thresholds:\n",
    "            if value >= threshold:\n",
    "                return score\n",
    "        return 0  \n",
    "\n",
    "    # HR (Heart Rate)\n",
    "    news += assign_news_score(row.get('HR', 0), [(40, 3), (50, 1), (90, 0), (110, 1), (130, 2), (131, 3)])\n",
    "\n",
    "    # Respiration Rate\n",
    "    news += assign_news_score(row.get('Resp', 0), [(8, 3), (9, 1), (11, 0), (21, 2), (24, 3)])\n",
    "\n",
    "    # Temperature\n",
    "    news += assign_news_score(row.get('Temp', 0), [(35, 3), (36, 1), (38, 1), (39.1, 2)])\n",
    "\n",
    "    # SBP (Systolic BP) or MAP (Mean Arterial Pressure)\n",
    "    sbp = row.get('SBP', row.get('MAP', 100))\n",
    "    news += assign_news_score(sbp, [(90, 3), (100, 2), (110, 1)])\n",
    "\n",
    "    # O2 Saturation\n",
    "    news += assign_news_score(row.get('O2Sat', 0), [(85, 3), (91, 2), (93, 1)])\n",
    "\n",
    "    # Supplemental Oxygen (if available)\n",
    "    if row.get('FiO2', 0) > 0.21:\n",
    "        news += 2\n",
    "\n",
    "    return news\n",
    "\n",
    "def calculate_qsofa(row):\n",
    "    qsofa = 0\n",
    "\n",
    "    # SBP ≤ 100 mmHg\n",
    "    if row.get('SBP', 120) <= 100:\n",
    "        qsofa += 1\n",
    "\n",
    "    # Respiration Rate ≥ 22\n",
    "    if row.get('Resp', 0) >= 22:\n",
    "        qsofa += 1\n",
    "\n",
    "    return qsofa\n",
    "\n",
    "def num_recorded_values(row):\n",
    "    recorded_measurements = df.notnull().sum()\n",
    "\n",
    "    return recorded_measurements\n",
    "\n",
    "def missingness_feature(row):\n",
    "    \n",
    "    if 'ICULOS' and 'ICULOS' in df.columns:\n",
    "        df = df.sort_values(by='ICULOS')\n",
    "        time_intervals = df['ICULOS'].diff()\n",
    "\n",
    "    return time_intervals\n",
    "\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    #Adds rolling statistics (moving averages, standard deviation, rate of change) for some features (may or may not be useful).\n",
    "    time_window_sizes = [3, 6, 12]  # Rolling window sizes (in time steps)\n",
    "    feature_cols = ['HeartRate', 'RespiratoryRate', 'MAP', 'SpO2', 'Creatinine', 'Platelets']\n",
    "\n",
    "    df.sort_values(['patient_id', 'ICULOS'], inplace=True)\n",
    "\n",
    "    for col in feature_cols:\n",
    "        if col in df.columns:\n",
    "            for window in time_window_sizes:\n",
    "                df[f'{col}_MA_{window}h'] = df.groupby('patient_id')[col].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "                df[f'{col}_SD_{window}h'] = df.groupby('patient_id')[col].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "                df[f'{col}_Delta'] = df.groupby('patient_id')[col].diff()\n",
    "    return df\n",
    "\n",
    "def preprocess_data(output_file):\n",
    "    global df \n",
    "\n",
    "    df['SOFA'] = df.apply(calculate_sofa, axis=1)\n",
    "    df['NEWS'] = df.apply(calculate_news, axis=1)\n",
    "    df['qSOFA'] = df.apply(calculate_qsofa, axis=1)\n",
    "    #df['num_recorded_values'] = df.apply(num_recorded_values, axis=1)\n",
    "    #df['missingness_feature'] = df.apply(missingness_feature, axis=1)\n",
    "    df = add_temporal_features(df)\n",
    "\n",
    "    if 'Gender' in df.columns:\n",
    "        df['Gender'] = LabelEncoder().fit_transform(df['Gender'].astype(str))\n",
    "\n",
    "    feature_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    scaler = MinMaxScaler()\n",
    "    df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "    df.to_parquet(output_file, index=False)\n",
    "\n",
    "    print(f\"Preprocessed data saved to {output_file}\")\n",
    "\n",
    "output_file = \"preprocessed_data.parquet\"\n",
    "preprocess_data(output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-sepsis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

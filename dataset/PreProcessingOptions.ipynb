{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below for the FULL feature engineered file with SOFA, NEWS, qSOFA, temporal sliding windows. If you're wanting feature reduction you need to also run the ones below this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/phhhw5y577vd2cqvhz66d2640000gp/T/ipykernel_73891/4140127142.py:138: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to preprocessed_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "os.chdir(\"/Users/kashishgupta/Documents/DS2025/dl-sepsis-prediction\") \n",
    "file_path = \"dataset/imputed_combined_data.parquet\" \n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "file_path_NANS = \"dataset/raw_combined_data.parquet\"\n",
    "df2 = pd.read_parquet(file_path_NANS)\n",
    "\n",
    "df.head()\n",
    "\n",
    "max_length = df.groupby(\"patient_id\").size().max()\n",
    "\n",
    "# Score Calculation\n",
    "def calculate_sofa(row):\n",
    "    sofa = 0\n",
    "\n",
    "    def assign_score(value, thresholds):\n",
    "        for threshold, score in thresholds:\n",
    "            if value >= threshold:\n",
    "                return score\n",
    "        return 0  \n",
    "\n",
    "    # Respiration \n",
    "    if row.get('FiO2', 0) > 0:\n",
    "        pao2_fio2 = row.get('SaO2', 0) / row['FiO2']\n",
    "        sofa += assign_score(pao2_fio2, [(100, 4), (200, 3), (300, 2), (400, 1)])\n",
    "\n",
    "    # Coagulation\n",
    "    sofa += assign_score(row.get('Platelets', float('inf')), [(20, 4), (50, 3), (100, 2), (150, 1)])\n",
    "\n",
    "    # Liver Function\n",
    "    sofa += assign_score(row.get('Bilirubin_total', 0), [(12, 4), (6, 3), (2, 2), (1.2, 1)])\n",
    "\n",
    "    # Cardiovascular\n",
    "    if row.get('MAP', 100) < 70:\n",
    "        sofa += 1\n",
    "\n",
    "    # Renal Function\n",
    "    sofa += assign_score(row.get('Creatinine', 0), [(5, 4), (3.5, 3), (2, 2), (1.2, 1)])\n",
    "\n",
    "    return sofa\n",
    "\n",
    "def calculate_news(row):\n",
    "    news = 0\n",
    "\n",
    "    def assign_news_score(value, thresholds):\n",
    "        for threshold, score in thresholds:\n",
    "            if value >= threshold:\n",
    "                return score\n",
    "        return 0  \n",
    "\n",
    "    # HR (Heart Rate)\n",
    "    news += assign_news_score(row.get('HR', 0), [(40, 3), (50, 1), (90, 0), (110, 1), (130, 2), (131, 3)])\n",
    "\n",
    "    # Respiration Rate\n",
    "    news += assign_news_score(row.get('Resp', 0), [(8, 3), (9, 1), (11, 0), (21, 2), (24, 3)])\n",
    "\n",
    "    # Temperature\n",
    "    news += assign_news_score(row.get('Temp', 0), [(35, 3), (36, 1), (38, 1), (39.1, 2)])\n",
    "\n",
    "    # SBP (Systolic BP) or MAP (Mean Arterial Pressure)\n",
    "    sbp = row.get('SBP', row.get('MAP', 100))\n",
    "    news += assign_news_score(sbp, [(90, 3), (100, 2), (110, 1)])\n",
    "\n",
    "    # O2 Saturation\n",
    "    news += assign_news_score(row.get('O2Sat', 0), [(85, 3), (91, 2), (93, 1)])\n",
    "\n",
    "    # Supplemental Oxygen (if available)\n",
    "    if row.get('FiO2', 0) > 0.21:\n",
    "        news += 2\n",
    "\n",
    "    return news\n",
    "\n",
    "def calculate_qsofa(row):\n",
    "    qsofa = 0\n",
    "\n",
    "    # SBP ≤ 100 mmHg\n",
    "    if row.get('SBP', 120) <= 100:\n",
    "        qsofa += 1\n",
    "\n",
    "    # Respiration Rate ≥ 22\n",
    "    if row.get('Resp', 0) >= 22:\n",
    "        qsofa += 1\n",
    "\n",
    "    return qsofa\n",
    "\n",
    "def num_recorded_values(row):\n",
    "    recorded_measurements = df.notnull().sum()\n",
    "\n",
    "    return recorded_measurements\n",
    "\n",
    "def missingness_feature(row):\n",
    "    \n",
    "    if 'ICULOS' and 'ICULOS' in df.columns:\n",
    "        df = df.sort_values(by='ICULOS')\n",
    "        time_intervals = df['ICULOS'].diff()\n",
    "\n",
    "    return time_intervals\n",
    "\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    #Adds rolling statistics (moving averages, standard deviation, rate of change) for some features (may or may not be useful).\n",
    "    time_window_sizes = [3, 6, 12]  # Rolling window sizes (in time steps)\n",
    "    feature_cols = ['HeartRate', 'RespiratoryRate', 'MAP', 'SpO2', 'Creatinine', 'Platelets']\n",
    "\n",
    "    df.sort_values(['patient_id', 'ICULOS'], inplace=True)\n",
    "\n",
    "    for col in feature_cols:\n",
    "        if col in df.columns:\n",
    "            for window in time_window_sizes:\n",
    "                df[f'{col}_MA_{window}h'] = df.groupby('patient_id')[col].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "                df[f'{col}_SD_{window}h'] = df.groupby('patient_id')[col].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "                df[f'{col}_Delta'] = df.groupby('patient_id')[col].diff()\n",
    "    return df\n",
    "\n",
    "def preprocess_data(output_file):\n",
    "    global df \n",
    "\n",
    "    df['SOFA'] = df.apply(calculate_sofa, axis=1)\n",
    "    df['NEWS'] = df.apply(calculate_news, axis=1)\n",
    "    df['qSOFA'] = df.apply(calculate_qsofa, axis=1)\n",
    "    #df['num_recorded_values'] = df.apply(num_recorded_values, axis=1)\n",
    "    #df['missingness_feature'] = df.apply(missingness_feature, axis=1)\n",
    "    df = add_temporal_features(df)\n",
    "\n",
    "    if 'Gender' in df.columns:\n",
    "        df['Gender'] = LabelEncoder().fit_transform(df['Gender'].astype(str))\n",
    "\n",
    "    feature_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    scaler = MinMaxScaler()\n",
    "    df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "    df = df.fillna(method=\"bfill\")\n",
    "\n",
    "    df.to_parquet(output_file, index=False)\n",
    "\n",
    "    print(f\"Preprocessed data saved to {output_file}\")\n",
    "\n",
    "output_file = \"preprocessed_data.parquet\"\n",
    "preprocess_data(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're wanting the PCA analysis dataset run the code below to save it as pca_preprocessed.parquet in YOUR files (Github says file too large now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "os.chdir(\"/Users/kashishgupta/Documents/DS2025/dl-sepsis-prediction\") \n",
    "\n",
    "file_path = \"preprocessed_data.parquet\" \n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "X = df.drop(columns=[\"SepsisLabel\", \"patient_id\", \"dataset\", \"cluster_id\"])\n",
    "X = X.fillna(method=\"bfill\")\n",
    "print(X.var())\n",
    "print(X.dtypes)\n",
    "y = df[\"SepsisLabel\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=0.95)  # Keeping 95% of variance - adjust if you want less/more original data representation\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Original Features: {X.shape[1]}, Reduced Features: {X_pca.shape[1]}\")\n",
    "print (X_pca)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.cumsum(explained_variance_ratio), marker=\"o\", linestyle=\"--\")\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA Explained Variance\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "X_pca_df = pd.DataFrame(X_pca)\n",
    "\n",
    "# Save the DataFrame as a Parquet file\n",
    "X_pca_df.to_parquet(\"pca_preprocessed.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below for feature selection, this is based on SHAP values + preliminary model training to see which features were most impactful + what is the optimal number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"preprocessed_data.parquet\" \n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "X = df.drop(columns=[\"SepsisLabel\", \"patient_id\", \"dataset\", \"cluster_id\", \"Unit2\", \"Gender\", \"Platelets_Delta\", \"Creatinine_Delta\", \"Platelets_SD_3h\", \"Hct\", \"MAP_Delta\", \"MAP_SD_3h\", \"Creatinine_MA_3h\", \"Creatinine_SD_3h\", \"Platelets\"])\n",
    "X.to_parquet(\"feature_selection_preprocessed.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
